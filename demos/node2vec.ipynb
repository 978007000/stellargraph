{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a mockup of node2vec model created with stellar graph ml library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import stellar_ml as sml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "- Load a graph with GraphLoader\n",
    "- Create an instance of random walk generator (class imported from the library); generate random walks on the graph, return random_walks\n",
    "- Create an instance of (node,context) pairs generator (class imported from the library), connect to random_walks\n",
    "- Build a tensorflow model for word2vec:\n",
    "    - create placeholders for the input (node,context) pairs\n",
    "    - create the layers: embeddings, context_softmax - use layers from the library, or layers from tf or keras?\n",
    "    - create the loss:\n",
    "            nce_loss = tf.reduce_mean(\n",
    "                       tf.nn.nce_loss(weights=nce_weights,\n",
    "                       biases=nce_biases,\n",
    "                       labels=train_context,\n",
    "                       inputs=embed,\n",
    "                       num_sampled=num_sampled,\n",
    "                       num_classes=vocabulary_size))\n",
    "    - create an optimizer\n",
    "- Train the word2vec model in a session\n",
    "    - create minibatches of (node,context) pairs using the generator\n",
    "    - loop through the minibatches, feeding them to the model\n",
    "    - optimise the model's loss\n",
    "    - repeat for n_epoch epochs\n",
    "- Extract the final node embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sml.graphloader.load('path/to/graph')  # this should support multiple graph formats: EPGM, networkx, graphml, and\n",
    "                                            # the result should be a networkx graph (probably the most general MultiDiGraph)\n",
    "    \n",
    "assert hasattr(g, 'graph')   # G should be a networkx graph object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of graph random walk generator, and use it to generate random walks on g:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = sml.graph_exploration.UniformRandomWalk(g, numWalks, walkLength, p, q, seed)\n",
    "walks = rw.generate()   # perform random walks on g and return a list of walks (node sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RSEED = 42\n",
    "batch_size = 128\n",
    "num_skips = 2\n",
    "skip_window = 1\n",
    "\n",
    "embedding_size = 128\n",
    "\n",
    "vocab_size = len(set(walks))    # number of unique nodes\n",
    "\n",
    "skipgram_batchgen = sml.SkipGram(data=walks, batch_size=batch_size, num_skips=num_skips, skip_window=skip_window)  # create an instance of skipgram batch generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tensorflow model for word2vec using sml.W2V_Sampled() class (e.g., the one defined in Andrew's node2vec_pregen.py code https://github.com/adocherty/node2vec_experiments), if this class is part of the sml library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = sml.W2V_Sampled(\n",
    "        embedding_size=embedding_size,\n",
    "        vocabulary_size=vocab_size,\n",
    "        batch_size=batch_size,\n",
    "        val_batch_size=None,\n",
    "        neg_samples=2,\n",
    "        save_path=\"n2v_{}\".format(datetime.date.today()),\n",
    "        learning_rate=0.2\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if W2V_Sampled() is NOT a part of the sml library, build a word2vec model (the tensorflow computation graph and the .train method) using tensorflow or Keras layers..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the word2vec model by feeding to it batches generated with skipgram_batchgen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_context_indices = None\n",
    "freeze_indices = None\n",
    "checkpoint_file = None\n",
    "\n",
    "with tf.Session() as session, tf.device('/cpu:0'):\n",
    "    tf.set_random_seed(RSEED)\n",
    "\n",
    "    word2vec.train(session, skipgram_batchgen,\n",
    "                   freeze_indices=freeze_indices,\n",
    "                   freeze_context_indices=freeze_context_indices,\n",
    "                   restore_from_file=checkpoint_file,\n",
    "                   n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
