{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Link/edge prediction demo for cora dataset (homegeneous network) where all nodes are papers and edges between nodes are citation links, e.g., paper A cites paper B. \n",
    "\n",
    "Each paper has a **subject** attribute with one of 7 values denoting the subject area of the paper.\n",
    "\n",
    "This demo notebook **demonstrates how to predict citation links/edges between papers** using the random walk-based representation learning method Node2Vec.\n",
    "\n",
    "**References:** \n",
    "\n",
    "**[1]** Node2Vec: Scalable Feature Learning for Networks. A. Grover, J. Leskovec. ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), 2016. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from math import isclose\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from stellargraph.data.edge_splitter import EdgeSplitter\n",
    "from utils.cl_arguments_parser import parse_args\n",
    "from utils.read_graph import read_graph\n",
    "from utils.predictors import *\n",
    "from collections import Counter\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameters for Node2Vec\n",
    "parameters = {\n",
    "    \"p\": 1.,  # Parameter p\n",
    "    \"q\": 1.,  # Parameter q\n",
    "    \"dimensions\": 128,  # dimensionality of node2vec embeddings\n",
    "    \"num_walks\": 10,  # Number of walks from each node\n",
    "    \"walk_length\": 80,  # Walk length\n",
    "    \"window_size\": 10,  # Context size for word2vec\n",
    "    \"iter\": 1,  # number of SGD iterations (epochs)\n",
    "    \"workers\": multiprocessing.cpu_count(),  # number of workers for word2vec\n",
    "    \"weighted\": False,  # is graph weighted?\n",
    "    \"directed\": False,  # are edges directed?\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "\n",
    "The dataset is the citation network Cora.\n",
    "\n",
    "It can be downloaded by clicking [here](https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz)\n",
    "\n",
    "The following is the description of the dataset from the publisher,\n",
    "\n",
    "> The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words. The README file in the dataset provides more details. \n",
    "\n",
    "For this demo, we ignore the word vector associated with each paper. We are only interested in the network structure.\n",
    "\n",
    "Download and unzip the cora.tgz file to a location on your computer. For the purposes of this demo, we are only interested in the **cora.cites** file that is a representation of the graph as an edge list.\n",
    "\n",
    "We assume that the dataset is stored in the directory\n",
    "\n",
    "`~/data/cora/cora.cites`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_location = os.path.expanduser(\"~/data/cora/cora.cites\")\n",
    "dataset_name = 'cora'\n",
    "g_nx = read_graph(graph_file=cora_location, dataset_name=dataset_name)\n",
    "\n",
    "# Select the largest connected component. For clarity we ignore isolated\n",
    "# nodes and subgraphs; having these in the data does not prevent the\n",
    "# algorithm from running and producing valid results.\n",
    "g_nx = max(nx.connected_component_subgraphs(g_nx, copy=True), key=len)\n",
    "print(\"Largest subgraph statistics: {} nodes, {} edges\".format(\n",
    "    g_nx.number_of_nodes(), g_nx.number_of_edges()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct train and test splits of the input data\n",
    "\n",
    "We are going to tackle link prediction as a supervised learning problem whereas we are going to train a binary classifier to predict a link, or not, between to nodes in the graph. \n",
    "\n",
    "For supervised classification, we need a training set of positive and negative examples of links and a corresponding **train** graph with the positive links removed; this graph is used for representation learning.\n",
    "\n",
    "For evaluation, we will use a hold out dataset, that is a set of positive and negative examples of links and a corresponding **test** graph.\n",
    "\n",
    "We are going to split our input graph into a **train** and **test** graphs using the EdgeSplitter class in stellar.data.edge_splitter. We are going to use the **train** graph for training the predictive model (a binary classifier that given two nodes it will predict whether a link between these two nodes should exist or not) and the **test** graph for evaluating the predictive model's performance on hold out data. \n",
    "\n",
    "Each graph will have the same number of nodes as the input graph but the number of edges will differ as some of the edges will be removed during each split and used as the positive samples for training the link prediction classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test graph and edge test data\n",
    "edge_splitter_test = EdgeSplitter(g_nx)\n",
    "g_test, edge_data_ids_test, edge_data_labels_test = edge_splitter_test.train_test_split( \n",
    "    p=0.1, method='global'\n",
    ")\n",
    "\n",
    "# Train graph and edge train data\n",
    "edge_splitter_train = EdgeSplitter(g_test, g_nx)\n",
    "g_train, edge_data_ids_train, edge_data_labels_train = edge_splitter_train.train_test_split(\n",
    "    p=0.1, method='global'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert graphs\n",
    "\n",
    "The node2vec reference implementation requires that the given graph is undirected and homogeneous. We cast the **train** and **test** graphs accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test graphs should be of type nx.Graph\n",
    "g_test = nx.Graph(g_test)\n",
    "g_train = nx.Graph(g_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the link prediction model and evaluate on test data\n",
    "\n",
    "We are going to train a link prediction classifier in three steps. \n",
    "1. We use Node2Vec, [1], to calculate node embeddings. These embeddings are learned in such a way to ensure that nodes that are close in the graph remain close in the embedding space.\n",
    "2. We calculate link/edge embeddings for the positive and negative edge samples by applying a binary operator on the embeddings of the source and target nodes of each sampled edge. We consider 4 different operators, hadamard, l1, l2, and average; the paper in [1] provides a detailed description of these operators. All operators produce link embeddings that have equal dimensionality to the input node embeddings (128 dimensions for our example.) \n",
    "3. Given the embeddings of the positive and negative examples, we train a logistic regression classifier to predict a binary value indicating whether an edge between two nodes should exist or not.\n",
    "4. We evaluate the performance of the link classifier for each of the 4 operators on the training data and select the best performing one. The selected operator is used to predict the hold out, test, data with node embeddings calculated on the **test** graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fl, test_fl, clf_edge = train_homogeneous_graph(\n",
    "    g_train=g_train,\n",
    "    g_test=g_test,\n",
    "    output_node_features='embeddings.emb',\n",
    "    edge_data_ids_train=edge_data_ids_train,\n",
    "    edge_data_labels_train=edge_data_labels_train,\n",
    "    edge_data_ids_test=edge_data_ids_test,\n",
    "    edge_data_labels_test=edge_data_labels_test,\n",
    "    parameters=parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise representations of link embeddings\n",
    "\n",
    "Learned link embeddings have 128 dimensions but for visualisation we project them down to 2 dimensions using the t-SNE algorithm ([link](https://lvdmaaten.github.io/tsne/)). \n",
    "\n",
    "Green points represent positive edges and red points represent negative (no edge should exist between the corresponding vertices) edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate edge features for test data\n",
    "edge_data = (edge_data_ids_test, edge_data_labels_test)\n",
    "X, y = test_fl.transform(edge_data, 'h')\n",
    "\n",
    "# Learn a projection from 128 dimensions to 2\n",
    "tsne = TSNE(n_components=2, init='random', random_state=0)\n",
    "X_transformed = tsne.fit_transform(X)\n",
    "\n",
    "# plot the 2-dimensional points\n",
    "red = y == 0\n",
    "green = y == 1\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.scatter(X_transformed[red, 0], X_transformed[red, 1], c=\"r\")\n",
    "plt.scatter(X_transformed[green, 0], X_transformed[green, 1], c=\"g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example has demonstrated how to use stellar-ml to build a link prediction algorithm for homogeneous graphs using the Node2Vec, [1], representation learning algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
