{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link prediction demo for cora dataset (homegeneous network) where all nodes are papers and edges between nodes are citation links, e.g., paper A cites paper B. \n",
    "\n",
    "Each paper has a **subject** attribute with one of 7 values denoting the subject area of the paper.\n",
    "\n",
    "This demo notebook demonstrates how to predict citation links between papers using the random walk-based representation learning method Node2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import multiprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# stellar ml library imports\n",
    "from stellar.data.epgm import EPGM\n",
    "from stellar.data.edge_splitter import EdgeSplitter\n",
    "# Node2Vec representation learning\n",
    "from utils.node2vec_feature_learning import Node2VecFeatureLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameters for Node2Vec\n",
    "parameters = {\n",
    "    \"p\": 1.,  # Parameter p\n",
    "    \"q\": 1.,  # Parameter q\n",
    "    \"dimensions\": 128,  # dimensionality of node2vec embeddings\n",
    "    \"num_walks\": 10,  # Number of walks from each node\n",
    "    \"walk_length\": 80,  # Walk length\n",
    "    \"window_size\": 10,  # Context size for word2vec\n",
    "    \"iter\": 1,  # number of SGD iterations (epochs)\n",
    "    \"workers\": multiprocessing.cpu_count(),  # number of workers for word2vec\n",
    "    \"weighted\": False,  # is graph weighted?\n",
    "    \"directed\": False,  # are edges directed?\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_graph(graph_file, dataset_name):\n",
    "    \"\"\"\n",
    "    Reads the input network in networkx.\n",
    "\n",
    "    Args:\n",
    "        graph_file: The directory where graph in EPGM format is stored.\n",
    "        dataset_name: The name of the graph selected out of all the graph heads in EPGM file.\n",
    "\n",
    "    Returns:\n",
    "        The graph in networkx format\n",
    "    \"\"\"\n",
    "    try:  # assume args.input points to an EPGM graph\n",
    "        G_epgm = EPGM(graph_file)\n",
    "        graphs = G_epgm.G[\"graphs\"]\n",
    "        if (\n",
    "            dataset_name is None\n",
    "        ):  # if dataset_name is not given, use the name of the 1st graph head\n",
    "            dataset_name = graphs[0][\"meta\"][\"label\"]\n",
    "            print(\n",
    "                \"WARNING: dataset name not specified, using dataset '{}' in the 1st graph head\".format(\n",
    "                    dataset_name\n",
    "                )\n",
    "            )\n",
    "        graph_id = None\n",
    "        for g in graphs:\n",
    "            if g[\"meta\"][\"label\"] == dataset_name:\n",
    "                graph_id = g[\"id\"]\n",
    "\n",
    "        g = G_epgm.to_nx(graph_id, parameters[\"directed\"])\n",
    "        if parameters[\"weighted\"]:\n",
    "            raise NotImplementedError\n",
    "        else:\n",
    "            # This is the correct way to set the edge weight in a MultiGraph.\n",
    "            edge_weights = {e: 1 for e in g.edges(keys=True)}\n",
    "            nx.set_edge_attributes(g, \"weight\", edge_weights)\n",
    "    except:  # otherwise, assume arg.input points to an edgelist file\n",
    "        if parameters[\"weighted\"]:\n",
    "            g = nx.read_edgelist(\n",
    "                graph_file,\n",
    "                nodetype=int,\n",
    "                data=((\"weight\", float),),\n",
    "                create_using=nx.DiGraph(),\n",
    "            )\n",
    "        else:\n",
    "            g = nx.read_edgelist(graph_file, nodetype=int, create_using=nx.DiGraph())\n",
    "            for edge in g.edges():\n",
    "                g[edge[0]][edge[1]][\"weight\"] = 1  # {'weight': 1}\n",
    "\n",
    "        if not parameters[\"directed\"]:\n",
    "            g = g.to_undirected()\n",
    "\n",
    "    print(\n",
    "        \"Graph statistics: {} nodes, {} edges\".format(\n",
    "            g.number_of_nodes(), g.number_of_edges()\n",
    "        )\n",
    "    )\n",
    "    return g\n",
    "\n",
    "\n",
    "def print_distance_probabilities(node_distances):\n",
    "    counts = Counter(node_distances)\n",
    "    d_total = sum(counts.values())\n",
    "    counts_normalized = {k: v / d_total for k, v in counts.items()}\n",
    "    counts_normalized = sorted(counts_normalized.items(), key=lambda x: x[0])\n",
    "    counts = [v for k, v in counts_normalized]\n",
    "    print(\n",
    "        \"Normalized distances between source and target nodes in negative samples: {}\".format(\n",
    "            counts\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def link_prediction_clf(feature_learner, edge_data, binary_operators=None):\n",
    "    \"\"\"\n",
    "    Performs link prediction given that node features have already been computed. It uses the node features to\n",
    "    derive edge features using the operators given. Then it trains a Logistic Regression classifier to predict\n",
    "    links between nodes.\n",
    "\n",
    "    Args:\n",
    "        feature_learner: Representation learning object.\n",
    "        edge_data: (2-tuple) Positive and negative edge data for training the classifier\n",
    "        binary_operators: Binary operators applied on node features to produce the corresponding edge feature.\n",
    "\n",
    "    Returns:\n",
    "        Returns the ROCAUC score achieved by the classifier for each of the specified binary operators.\n",
    "    \"\"\"\n",
    "    scores = []  # the auc values for each binary operator (based on test set performance)\n",
    "    clf_best = None\n",
    "    score_best = 0\n",
    "    op_best = \"\"\n",
    "\n",
    "    if binary_operators is None:\n",
    "        print(\"WARNING: Using default binary operator 'h'\")\n",
    "        binary_operators = [\"h\"]\n",
    "\n",
    "    # for each type of binary operator\n",
    "    for binary_operator in binary_operators:\n",
    "        X, y = feature_learner.transform(edge_data, binary_operator)\n",
    "        #\n",
    "        # Split the data and keep X_test, y_test for scoring the model; setting the random_state to\n",
    "        # the same constant for every iteration gives the same split of data so the comparison is fair.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, train_size=0.75, test_size=0.25\n",
    "        )\n",
    "        # LogisticRegressionCV automatically tunes the parameter C using cross validation and the ROC AUC metric\n",
    "        clf = Pipeline(\n",
    "            steps=[\n",
    "                (\"sc\", StandardScaler()),\n",
    "                (\n",
    "                    \"clf\",\n",
    "                    LogisticRegressionCV(\n",
    "                        Cs=10, cv=10, scoring=\"roc_auc\", verbose=False\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = clf.predict_proba(X_test)  # predict on the test set\n",
    "        if clf.classes_[0] == 1:  # only needs probabilities of positive class\n",
    "            score_auc = roc_auc_score(y_test, y_pred[:, 0])\n",
    "        else:\n",
    "            score_auc = roc_auc_score(y_test, y_pred[:, 1])\n",
    "\n",
    "        if score_auc >= score_best:\n",
    "            score_best = score_auc\n",
    "            clf_best = clf\n",
    "            op_best = binary_operator\n",
    "\n",
    "        print(\n",
    "            \"Operator: {} Score (on test set of edge_data): {}\".format(\n",
    "                binary_operator, score_auc\n",
    "            )\n",
    "        )\n",
    "        scores.append({\"op\": binary_operator, \"score\": score_auc})\n",
    "\n",
    "    return scores, clf_best, op_best\n",
    "\n",
    "\n",
    "def predict_links(feature_learner, edge_data, clf, binary_operators=None):\n",
    "    \"\"\"\n",
    "    Given a node feature learner and a trained classifier, it computes edge features, uses the classifier to predict\n",
    "    the given edge data and calculate prediction accuracy.\n",
    "    :param feature_learner:\n",
    "    :param edge_data:\n",
    "    :param clf:\n",
    "    :param binary_operators:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if binary_operators is None:\n",
    "        print(\"WARNING: Using default binary operator 'h'\")\n",
    "        binary_operators = [\"h\"]\n",
    "\n",
    "    scores = []  # the auc values for each binary operator (based on test set performance)\n",
    "\n",
    "    # for each type of binary operator\n",
    "    for binary_operator in binary_operators:\n",
    "        # Derive edge features from node features using the given binary operator\n",
    "        X, y = feature_learner.transform(edge_data, binary_operator)\n",
    "        #\n",
    "        y_pred = clf.predict_proba(X)  # predict\n",
    "        if clf.classes_[0] == 1:  # only needs probabilities of positive class\n",
    "            score_auc = roc_auc_score(y, y_pred[:, 0])\n",
    "        else:\n",
    "            score_auc = roc_auc_score(y, y_pred[:, 1])\n",
    "\n",
    "        print(\"Prediction score:\", score_auc)\n",
    "        scores.append({\"op\": binary_operator, \"score\": score_auc})\n",
    "\n",
    "    return scores\n",
    "\n",
    "def train_homogeneous_graph(\n",
    "    g_train,\n",
    "    g_test,\n",
    "    output_node_features,  # filename for writing node embeddings\n",
    "    edge_data_ids_train,\n",
    "    edge_data_labels_train,  # train edge data\n",
    "    edge_data_ids_test,\n",
    "    edge_data_labels_test,  # test edge data\n",
    "):\n",
    "    # Using g_train and edge_data_train train a classifier for edge prediction\n",
    "    feature_learner_train = Node2VecFeatureLearning(\n",
    "        g_train, embeddings_filename=os.path.expanduser(output_node_features)\n",
    "    )\n",
    "    feature_learner_train.fit(\n",
    "        p=parameters[\"p\"],\n",
    "        q=parameters[\"q\"],\n",
    "        d=parameters[\"dimensions\"],\n",
    "        r=parameters[\"num_walks\"],\n",
    "        l=parameters[\"walk_length\"],\n",
    "        k=parameters[\"window_size\"],\n",
    "    )\n",
    "    # Train the classifier\n",
    "    binary_operators = [\"h\", \"avg\", \"l1\", \"l2\"]\n",
    "    scores_train, clf_edge, binary_operator = link_prediction_clf(\n",
    "        feature_learner=feature_learner_train,\n",
    "        edge_data=(edge_data_ids_train, edge_data_labels_train),\n",
    "        binary_operators=binary_operators,\n",
    "    )\n",
    "\n",
    "    # Do representation learning on g_test and use the previously trained classifier on g_train to predict\n",
    "    # edge_data_test\n",
    "    feature_learner_test = Node2VecFeatureLearning(\n",
    "        g_test, embeddings_filename=os.path.expanduser(output_node_features)\n",
    "    )\n",
    "    feature_learner_test.fit(\n",
    "        p=parameters[\"p\"],\n",
    "        q=parameters[\"q\"],\n",
    "        d=parameters[\"dimensions\"],\n",
    "        r=parameters[\"num_walks\"],\n",
    "        l=parameters[\"walk_length\"],\n",
    "        k=parameters[\"window_size\"],\n",
    "    )\n",
    "\n",
    "    scores = predict_links(\n",
    "        feature_learner=feature_learner_test,\n",
    "        edge_data=(edge_data_ids_test, edge_data_labels_test),\n",
    "        clf=clf_edge,\n",
    "        binary_operators=[binary_operator],\n",
    "    )\n",
    "\n",
    "    print(\"\\n  **** Scores on test set ****\\n\")\n",
    "    for score in scores:\n",
    "        print(\"     Operator: {}  Score: {:.2f}\".format(score[\"op\"], score[\"score\"]))\n",
    "    print(\"\\n  ****************************\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...reading /Users/eli024/Projects/data/cora/cora.epgm/graphs.json using utf-8 encoding...\n",
      "...reading /Users/eli024/Projects/data/cora/cora.epgm/vertices.json using utf-8 encoding...\n",
      "...reading /Users/eli024/Projects/data/cora/cora.epgm/edges.json using utf-8 encoding...\n",
      "Converting the EPGM graph 9ccd0dd106204767a723747a8b8d5b8a to NetworkX graph...\n",
      "Graph statistics: 2708 nodes, 5278 edges\n"
     ]
    }
   ],
   "source": [
    "cora_epgm_location = os.path.expanduser(\"~/Projects/data/cora/cora.epgm/\")\n",
    "dataset_name = 'cora'\n",
    "g_nx = read_graph(graph_file=cora_epgm_location, dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct train and test splits of the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Sampled 264 positive and 264 negative edges. **\n",
      "** Sampled 238 positive and 238 negative edges. **\n"
     ]
    }
   ],
   "source": [
    "# Test graph and edge test data\n",
    "edge_splitter_test = EdgeSplitter(g_nx)\n",
    "g_test, edge_data_ids_test, edge_data_labels_test = edge_splitter_test.train_test_split( \n",
    "    p=0.1, method='global'\n",
    ")\n",
    "\n",
    "# Train graph and edge train data\n",
    "edge_splitter_train = EdgeSplitter(g_test, g_nx)\n",
    "g_train, edge_data_ids_train, edge_data_labels_train = edge_splitter_train.train_test_split(\n",
    "    p=0.1, method='global'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train and Test graphs should be of type nx.Graph\n",
    "g_test = nx.Graph(g_test)\n",
    "g_train = nx.Graph(g_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the link prediction model and evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Node2VecFeatureLearning) Time for random walks 10 seconds\n",
      "(Node2VecFeatureLearning) Time for learning embeddings 9 seconds.\n",
      "Total time for fit() 18.34978222846985 seconds\n",
      "Operator: h Score (on test set of edge_data): 0.892312040700961\n",
      "Operator: avg Score (on test set of edge_data): 0.6427350427350427\n",
      "Operator: l1 Score (on test set of edge_data): 0.9440579710144927\n",
      "Operator: l2 Score (on test set of edge_data): 0.9595441595441595\n",
      "(Node2VecFeatureLearning) Time for random walks 10 seconds\n",
      "(Node2VecFeatureLearning) Time for learning embeddings 9 seconds.\n",
      "Total time for fit() 18.482025146484375 seconds\n",
      "Prediction score: 0.928790748393\n",
      "\n",
      "  **** Scores on test set ****\n",
      "\n",
      "     Operator: l2  Score: 0.93\n",
      "\n",
      "  ****************************\n"
     ]
    }
   ],
   "source": [
    "train_homogeneous_graph(\n",
    "    g_train=g_train,\n",
    "    g_test=g_test,\n",
    "    output_node_features='embeddings.emb',\n",
    "    edge_data_ids_train=edge_data_ids_train,\n",
    "    edge_data_labels_train=edge_data_labels_train,\n",
    "    edge_data_ids_test=edge_data_ids_test,\n",
    "    edge_data_labels_test=edge_data_labels_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (link-prediction)",
   "language": "python",
   "name": "link-prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
