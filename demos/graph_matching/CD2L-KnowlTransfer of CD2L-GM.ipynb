{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "  \n",
    "  \n",
    "**Note:** `CD2L-KnowlTransfer` corresponds to Section 4.2 in paper Cross-domain network representations [[2]](#refs).\n",
    "\n",
    "<a name=\"refs\"></a>  \n",
    "## References\n",
    "\n",
    "[1] Xue, Shan, Jie Lu, Guangquan Zhang, and Li Xiong. \"A framework of transferring structures across large-scale information networks.\" 2018 International Joint Conference on Neural Networks (IJCNN). IEEE, 2018. ([link](https://ieeexplore.ieee.org/abstract/document/8489037))\n",
    "\n",
    "[2] Xue, Shan, Jie Lu, and Guangquan Zhang. \"Cross-domain network representations.\" Pattern Recognition 94 (2019): 135-148. ([link](https://www.sciencedirect.com/science/article/pii/S0031320319301852))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from stellargraph.data import BiasedRandomWalk\n",
    "from stellargraph import StellarGraph\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose a case to run the notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'merge'\n",
    "# case = 'split'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset  \n",
    "\n",
    "The dataset is the citation network Cora. It can be downloaded by clicking [here](https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz). The following is the description of the dataset from the publisher:\n",
    "\n",
    "> The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words. The README file in the dataset provides more details. \n",
    "\n",
    "For this demo, we ignore the word vectors associated with each paper. We are only interested in the network structure and the **subject** attribute of each paper.\n",
    "\n",
    "Download and unzip the cora.tgz file to a location on your computer. \n",
    "\n",
    "We assume that the dataset is stored in the directory\n",
    "\n",
    "`~/data/cora/`\n",
    "\n",
    "where the files `cora.cites` and `cora.content` can be located.\n",
    "\n",
    "We are going to load the data into a networkx object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"~/data/cora\"\n",
    "data_dir = \"~/Desktop/stellargraph/data/cora\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph statistics: 2708 nodes, 5278 edges\n"
     ]
    }
   ],
   "source": [
    "# load directed graph from ordering (cited_paper, citing_paper)\n",
    "data_location = os.path.expanduser(data_dir)\n",
    "g_nx = nx.read_edgelist(path=os.path.join(data_location,\"cora.cites\"), create_using=nx.DiGraph()).reverse()\n",
    "\n",
    "# convert to undirected graph for processing\n",
    "g_nx = g_nx.to_undirected()\n",
    "\n",
    "# load the node attribute data\n",
    "node_attr = pd.read_csv(os.path.join(data_location,\"cora.content\"), sep='\\t', header=None)\n",
    "values = { str(row.tolist()[0]): row.tolist()[-1] for _, row in node_attr.iterrows() }\n",
    "nx.set_node_attributes(g_nx, values, 'subject')\n",
    "\n",
    "print(\"Graph statistics: {} nodes, {} edges\".format(\n",
    "    g_nx.number_of_nodes(), g_nx.number_of_edges()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data Preparation for Source and Target Graph  \n",
    "\n",
    "We select the largest connected component as **Source Graph** and the second largest connected component as **Target Graph**.   \n",
    "\n",
    "Case1: Data for Merge  \n",
    "Case2: Data for Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest subgraph (source graph) statistics: 2485 nodes, 5069 edges\n",
      "Target graph number of nodes threshold: 248\n",
      "Smaller subgraph (target graph) statistics: 26 nodes, 43 edges\n"
     ]
    }
   ],
   "source": [
    "# For clarity we ignore isolated nodes and subgraphs; having these in the data does not prevent the\n",
    "# algorithm from running and producing valid results.v_no_s\n",
    "\n",
    "g_nx_ccs = ( g_nx.subgraph(c).copy() for c in nx.connected_components(g_nx) )\n",
    "\n",
    "if case is 'merge':\n",
    "    # Select the largest connected component as the source graph. \n",
    "    g_nx_s = max(g_nx_ccs, key=len)\n",
    "    v_no_s = g_nx_s.number_of_nodes()\n",
    "    print(\"Largest subgraph (source graph) statistics: {} nodes, {} edges\".format(\n",
    "        v_no_s, g_nx_s.number_of_edges()))\n",
    "    \n",
    "    # Select a smaller connected component as the target graph. \n",
    "    # Assumption one: target graph node scale < source graph node scale\n",
    "    threshold = int(v_no_s / 10)\n",
    "    print(\"Target graph number of nodes threshold: {}\".format(threshold))\n",
    "    \n",
    "    g_nx_ccs_t = ( g_nx.subgraph(c).copy() for c in nx.connected_components(g_nx) \n",
    "                  if g_nx.subgraph(c).copy().number_of_nodes() < threshold)\n",
    "    g_nx_t = max(g_nx_ccs_t, key=len)\n",
    "    v_no_t = g_nx_t.number_of_nodes()\n",
    "    print(\"Smaller subgraph (target graph) statistics: {} nodes, {} edges\".format(\n",
    "        v_no_t, g_nx_t.number_of_edges()))\n",
    "    \n",
    "if case is 'split':\n",
    "    # Select the largest connected component as the target graph. \n",
    "    g_nx_t = max(g_nx_ccs, key=len)\n",
    "    v_no_t = g_nx_t.number_of_nodes()\n",
    "    print(\"Largest subgraph (target graph) statistics: {} nodes, {} edges\".format(\n",
    "        v_no_t, g_nx_t.number_of_edges()))\n",
    "    \n",
    "    # Select a smaller connected component as the source graph. \n",
    "    threshold = int(v_no_t / 10)\n",
    "    print(\"Source graph number of nodes threshold: {}\".format(threshold))\n",
    "    \n",
    "    g_nx_ccs_s = ( g_nx.subgraph(c).copy() for c in nx.connected_components(g_nx) \n",
    "                  if g_nx.subgraph(c).copy().number_of_nodes() < threshold)\n",
    "    g_nx_s = max(g_nx_ccs_s, key=len)\n",
    "    v_no_s = g_nx_s.number_of_nodes()\n",
    "    print(\"Smaller subgraph (source graph) statistics: {} nodes, {} edges\".format(\n",
    "        v_no_s, g_nx_s.number_of_edges()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Algorithm Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input 1:  Random Walks on Origial Source Graph by Node2Vec Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rw_s = BiasedRandomWalk(StellarGraph(g_nx_s))\n",
    "\n",
    "# walks_s = rw_s.run(\n",
    "#     nodes=list(g_nx_s.nodes()), # root nodes\n",
    "#     length=100,  # maximum length of a random walk\n",
    "#     n=10,        # number of random walks per root node \n",
    "#     p=0.5,       # Defines (unormalised) probability, 1/p, of returning to source node\n",
    "#     q=2.0        # Defines (unormalised) probability, 1/q, for moving away from source node\n",
    "# )\n",
    "# print(\"Number of random walks of source graph: {}\".format(len(walks_s)))\n",
    "\n",
    "# np.save('cora_walk_s_merge_case.npy', walks_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of random walks of source graph: 24850\n"
     ]
    }
   ],
   "source": [
    "walks_s = np.load('cora_walk_s_merge_case.npy')\n",
    "print(\"Number of random walks of source graph: {}\".format(len(walks_s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input 2: Weighted Target Graph\n",
    "\n",
    "Since the edges in the Cora dataset are unweighted, we need to synthetically add weights to the links in the graph. The weights are initialized in 1 and put on transfered weights afterwards by `CD2L-KnowlTransfer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u,v in g_nx_t.edges():\n",
    "    g_nx_t[u][v]['weight'] = 1\n",
    "\n",
    "# g_nx_t[list(g_nx_t.edges())[0][0]][list(g_nx_t.edges())[0][1]]['weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input 3: Cross Graph Links and Weights by CD2L-NodeBalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of cross graph edge set: (26, 9)\n",
      "shape of cross graph weight set: (26, 9)\n",
      "keys of supernodes: dict_keys(['supernode1', 'supernode2', 'supernode3', 'supernode4', 'supernode5', 'supernode6', 'supernode7', 'supernode8', 'supernode9'])\n"
     ]
    }
   ],
   "source": [
    "data = np.load('cora_NodeBalance_result_{}_case.npz'.format(case))\n",
    "\n",
    "e_cg = data['edge']\n",
    "w_cg = data['weight']\n",
    "supernode = data['supernode'].item()\n",
    "\n",
    "print(\"shape of cross graph edge set: {}\".format(e_cg.shape))\n",
    "print(\"shape of cross graph weight set: {}\".format(w_cg.shape))\n",
    "print(\"keys of supernodes: {}\".format(supernode.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Dataset Summary  \n",
    "\n",
    "| Graph | Number of Nodes  | Number of Edges | Average Degree |\n",
    "|------|------|------|------|\n",
    "|   Source Graph  | 2485 | 5069 | 4.080 |\n",
    "|   Target Graph  | 26   | 43   | 3.308 |\n",
    "|   Super Graph   | 9    | --   | --    |\n",
    "|   Target Cluster| 7    | --   | --    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Knowledge Transfer\n",
    "\n",
    "![CD2L-KnowlTransfer](knowltransfer.png)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of supernode ids index by node: 2485\n"
     ]
    }
   ],
   "source": [
    "id_v_to_sn = {node_id: sn_name for sn_name in supernode.keys() for node_id in supernode[sn_name]['node_ids']}\n",
    "print(\"number of supernode ids index by node: {}\".format(len(id_v_to_sn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of walks_sn: (24850, 100)\n"
     ]
    }
   ],
   "source": [
    "walks_sn = np.array([[str(id_v_to_sn[v_id]) for j,v_id in enumerate(walk)] for i,walk in enumerate(walks_s)])\n",
    "print(\"shape of walks_sn: {}\".format(walks_sn.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['supernode1', 'supernode7', 'supernode6', 'supernode7',\n",
       "       'supernode7', 'supernode7', 'supernode3', 'supernode7',\n",
       "       'supernode7', 'supernode8', 'supernode7', 'supernode8',\n",
       "       'supernode7', 'supernode8', 'supernode7', 'supernode8',\n",
       "       'supernode7', 'supernode7', 'supernode7', 'supernode7',\n",
       "       'supernode7', 'supernode7', 'supernode8', 'supernode8',\n",
       "       'supernode8', 'supernode8', 'supernode8', 'supernode7',\n",
       "       'supernode8', 'supernode7', 'supernode9', 'supernode8',\n",
       "       'supernode9', 'supernode8', 'supernode9', 'supernode8',\n",
       "       'supernode9', 'supernode8', 'supernode9', 'supernode8',\n",
       "       'supernode9', 'supernode8', 'supernode9', 'supernode7',\n",
       "       'supernode9', 'supernode7', 'supernode9', 'supernode8',\n",
       "       'supernode9', 'supernode8', 'supernode6', 'supernode7',\n",
       "       'supernode3', 'supernode7', 'supernode7', 'supernode7',\n",
       "       'supernode6', 'supernode7', 'supernode6', 'supernode7',\n",
       "       'supernode7', 'supernode7', 'supernode7', 'supernode8',\n",
       "       'supernode7', 'supernode8', 'supernode7', 'supernode8',\n",
       "       'supernode7', 'supernode8', 'supernode7', 'supernode8',\n",
       "       'supernode7', 'supernode7', 'supernode8', 'supernode7',\n",
       "       'supernode7', 'supernode8', 'supernode7', 'supernode8',\n",
       "       'supernode7', 'supernode7', 'supernode8', 'supernode7',\n",
       "       'supernode8', 'supernode8', 'supernode8', 'supernode8',\n",
       "       'supernode8', 'supernode8', 'supernode8', 'supernode8',\n",
       "       'supernode7', 'supernode8', 'supernode8', 'supernode8',\n",
       "       'supernode8', 'supernode8', 'supernode8', 'supernode8'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walks_sn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supernode_edge_and_weight(supernode,walks_s):\n",
    "    weight = np.zeros((len(supernode.keys()),len(supernode.keys())),dtype=np.float)\n",
    "    \n",
    "    return sn_w, sn_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_graph_weight(edge_t, v_ind_sn):\n",
    "    return cg_w_l, cg_w_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target_graph_weight(g_nx_t):\n",
    "    # part 1: weight on random walk over supernodes, sn_w\n",
    "    # part 2: cg_w (two sides)\n",
    "    \n",
    "    return g_nx_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Walk Distributions of Source and Target Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
